{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'graphviz'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-39cfb40e6eb1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcolorsys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mgraphviz\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplotting\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mscatter_matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'graphviz'"
     ]
    }
   ],
   "source": [
    "# Importem llibreries\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import colorsys\n",
    "import graphviz\n",
    "\n",
    "from pandas.plotting import scatter_matrix\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "from sklearn import cluster\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import datasets, neighbors, tree, svm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import classification_report, accuracy_score, plot_confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import export_graphviz\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.ensemble import ExtraTreesClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "from statsmodels.graphics.mosaicplot import mosaic\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "import json\n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.feature_selection import f_classif\n",
    "from matplotlib import pyplot\n",
    "import pickle\n",
    "from joblib import dump, load\n",
    "from mpl_toolkits.mplot3d.axes3d import Axes3D\n",
    "from plotly.offline import plot\n",
    "import plotly.graph_objs as go\n",
    "import plotly\n",
    "from sqlalchemy import create_engine \n",
    "from pandas import json_normalize\n",
    "%matplotlib inline\n",
    "plotly.offline.init_notebook_mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# DB Constants\n",
    "POSTGRES_ADDRESS = '45.76.81.71' \n",
    "POSTGRES_PORT = '5432' \n",
    "POSTGRES_USERNAME = 'airflow'\n",
    "POSTGRES_PASSWORD = 'airflow' \n",
    "POSTGRES_DBNAME = 'dominis'\n",
    "\n",
    "# Stablish connection\n",
    "postgres_str = ('postgresql://{username}:{password}@{ipaddress}:{port}/{dbname}'.format(username=POSTGRES_USERNAME, password=POSTGRES_PASSWORD, ipaddress=POSTGRES_ADDRESS, port=POSTGRES_PORT, dbname=POSTGRES_DBNAME)) \n",
    "conn = create_engine(postgres_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def concat_frames(frames_list):\n",
    "    return pd.concat(frames_list, axis=1)\n",
    "\n",
    "def add_value_labels(ax, spacing=5):\n",
    "    \"\"\"\n",
    "    Add labels to the end of each bar in a chart.\n",
    "    This function was created by justfortherecs and improved by the\n",
    "    author of this file.\n",
    "\n",
    "    Source: https://stackoverflow.com/questions/28931224/adding-value-labels-on-a-matplotlib-bar-chart\n",
    "    Arguments:\n",
    "        ax (matplotlib.axes.Axes): The matplotlib object containing the axes\n",
    "            of the plot to annotate.\n",
    "        spacing (int): The distance between the labels and the bars.\n",
    "    \"\"\"\n",
    "\n",
    "    # For each bar: Place a label\n",
    "    for rect in ax.patches:\n",
    "        # Get X and Y placement of label from rect.\n",
    "        y_value = rect.get_height()\n",
    "        x_value = rect.get_x() + rect.get_width() / 2\n",
    "\n",
    "        # Number of points between bar and label. Change to your liking.\n",
    "        space = spacing\n",
    "        # Vertical alignment for positive values\n",
    "        va = 'bottom'\n",
    "\n",
    "        # If value of bar is negative: Place label below bar\n",
    "        if y_value < 0:\n",
    "            # Invert space to place label below\n",
    "            space *= -1\n",
    "            # Vertically align label at top\n",
    "            va = 'top'\n",
    "\n",
    "        # Use Y value as label and format number with one decimal place\n",
    "        if isinstance(y_value, float):\n",
    "            #try:\n",
    "            #    label = int(y_value)\n",
    "            #except ValueError:\n",
    "            label = \"{:.2f}\".format(y_value)\n",
    "        else:\n",
    "            label = y_value\n",
    "\n",
    "        # Create annotation\n",
    "        ax.annotate(\n",
    "            label,                      # Use `label` as label\n",
    "            (x_value, y_value),         # Place label at end of the bar\n",
    "            xytext=(0, space),          # Vertically shift label by `space`--\n",
    "            textcoords=\"offset points\", # Interpret `xytext` as offset in points\n",
    "            ha='center',                # Horizontally center label\n",
    "            va=va)                      # Vertically align label differently for\n",
    "                                        # positive and negative values.\n",
    "\n",
    "    return ax\n",
    "\n",
    "def hist_groupby(df, var, category, alpha=0.6, ax=None):\n",
    "    \"\"\"\n",
    "    Method that creates a histogram divided by \n",
    "    a class variable (category)\n",
    "    \"\"\"\n",
    "    # Group by the class variable \"category\" and select the desired column\n",
    "    groups = df.groupby(category)[var]\n",
    "    \n",
    "    if ax is None:\n",
    "        # Create the plot\n",
    "        fig, ax = plt.subplots()\n",
    "\n",
    "    # For each group found for the variable \"category\" create a histogram and add it to the plot\n",
    "    for k, v in groups:\n",
    "        sns.distplot(v, ax=ax, label=k)\n",
    "        #v.dist(label=k, alpha=alpha, ax=ax)\n",
    "\n",
    "    # Activate the legend\n",
    "    ax.legend()\n",
    "    \n",
    "    # Set the title and axis\n",
    "    ax.set_title(\"{0} by {1}\".format(var, category))\n",
    "    ax.set_xlabel(var)\n",
    "    ax.set_ylabel(\"Frequency\")\n",
    "        \n",
    "    return ax\n",
    "\n",
    "class EstimatorSelectionHelper:\n",
    "\n",
    "    def __init__(self, models, params, scoring=['accuracy'], cv=5):\n",
    "        if not set(models.keys()).issubset(set(params.keys())):\n",
    "            missing_params = list(set(models.keys()) - set(params.keys()))\n",
    "            raise ValueError(\"Some estimators are missing parameters: %s\" % missing_params)\n",
    "        self.models = models\n",
    "        self.params = params\n",
    "        self.keys = models.keys()\n",
    "        self.grid_searches = {}\n",
    "        self.scoring = scoring\n",
    "        self.cv = cv\n",
    "\n",
    "    def fit(self, X, y, n_jobs=3, verbose=1, refit=False):\n",
    "        for key in self.keys:\n",
    "            print(\"Running GridSearchCV for %s.\" % key)\n",
    "            model = self.models[key]\n",
    "            params = self.params[key]\n",
    "            gs = GridSearchCV(model, params, cv=self.cv, n_jobs=n_jobs,\n",
    "                              verbose=verbose, scoring=self.scoring, refit=refit,\n",
    "                              return_train_score=True)\n",
    "            gs.fit(X,y)\n",
    "            self.grid_searches[key] = gs\n",
    "\n",
    "    def score_summary(self):\n",
    "        def row(key, scores, params):\n",
    "            d = {}\n",
    "            d['estimator'] = key\n",
    "            for score, values in scores.items():\n",
    "                d['min_score_{}'.format(score)] = min(values)\n",
    "                d['max_score_{}'.format(score)] = max(values)\n",
    "                d['mean_score_{}'.format(score)] = np.mean(values)\n",
    "                d['std_score_{}'.format(score)] = np.std(values)\n",
    "\n",
    "            return pd.Series({**params, **d})\n",
    "\n",
    "        rows = []\n",
    "        for k in self.grid_searches:\n",
    "            params = self.grid_searches[k].cv_results_['params']\n",
    "            scores_list = {}\n",
    "            for p_i, val in enumerate(params, start=0):\n",
    "                #print(\"PARAMS {} at index {}\".format(str(val), p_i))\n",
    "                scores_list[str(val)] = {}\n",
    "                for score in self.scoring:\n",
    "                    #print(\"SCORE: {}\".format(score))\n",
    "                    scores_list[str(val)][score] = []\n",
    "                    for i in range(0, self.cv):\n",
    "                        key = \"split{}_test_{}\".format(i, score)\n",
    "                        #print(\"KEY {}\".format(key))\n",
    "                        r = self.grid_searches[k].cv_results_[key]\n",
    "                        #print(\"VAL {} at index {}\".format(r, p_i))\n",
    "                        scores_list[str(val)][score].append(r[p_i])\n",
    "\n",
    "            for param in params:\n",
    "                rows.append((row(k, scores_list[str(param)], param)))\n",
    "        df = pd.DataFrame(rows)\n",
    "\n",
    "        score_cols = []\n",
    "        for score in self.scoring:\n",
    "            score_cols += ['min_score_{}'.format(score), 'mean_score_{}'.format(score), 'max_score_{}'.format(score), 'std_score_{}'.format(score)]\n",
    "        columns = ['estimator'] + score_cols\n",
    "        columns = columns + [c for c in df.columns if c not in columns]\n",
    "\n",
    "        return df[columns]\n",
    "\n",
    "    @staticmethod\n",
    "    def search_plot(df, score, x, y, ax=None):\n",
    "        # TODO:  An automatic search given the whole score_summary should be implemented.\n",
    "        df = df.pivot(index=y, columns=x, values=score)\n",
    "        return sns.heatmap(df, ax=ax)\n",
    "\n",
    "\n",
    "class PCAw(PCA):\n",
    "\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        PCA.__init__(self, *args, **kwargs)\n",
    "\n",
    "    def variance_plot(self, ax=None):\n",
    "        \"\"\"\n",
    "        Method that given a PCA instance\n",
    "        returns a plot with the relative\n",
    "        and accumulative variance.\n",
    "        \"\"\"\n",
    "        pc_variance_df = pd.DataFrame({\n",
    "            'accumulative_variance': np.cumsum(self.explained_variance_ratio_),\n",
    "            'relative_variance': self.explained_variance_ratio_\n",
    "            })\n",
    "\n",
    "        plot = pc_variance_df.plot(kind='bar', ax=ax)\n",
    "        plot.axhline(y=0.95, color='r', linestyle='--')\n",
    "        plot.set_title(\"PCA Explained variance\")\n",
    "        plot.set_xlabel(\"Principal Components\")\n",
    "        plot.set_ylabel(\"Variance\")\n",
    "\n",
    "        return plot\n",
    "\n",
    "    def plot_contribution(self, index, columns, ax=None):\n",
    "        eigenvalues=self.components_\n",
    "        pc=abs(eigenvalues[index,:])\n",
    "        contributions = pd.DataFrame({'contribution': pc}, index=columns)\n",
    "        ax = contributions.sort_values(by='contribution', ascending=False).plot(kind='bar', title=\"Contribution of variables to DIM {}\".format(index), ax=ax)\n",
    "        ax.axhline(y=0.1, color='r', linestyle='--')\n",
    "        return ax\n",
    "\n",
    "def plot_silhouette_method(df, k_min=2, k_max=10, ax=None):\n",
    "    silhouette = []\n",
    "    for k in range(k_min, k_max):\n",
    "        kmeans = cluster.KMeans(n_clusters=k)\n",
    "        clusters = kmeans.fit_predict(df)\n",
    "        silhouette.append(silhouette_score(df, clusters))\n",
    "    if ax is not None:\n",
    "        return ax.plot(range(k_min,k_max), silhouette, marker='o')\n",
    "    else:\n",
    "        return plt.plot(range(k_min,k_max), silhouette, marker='o')\n",
    "\n",
    "def plot_elbow_method(df, k_min=1, k_max=10, ax=None):\n",
    "    sse = []\n",
    "    # Apliquem KMeans pel rang de k especificat\n",
    "    for k in range(k_min, k_max):\n",
    "        kmeans = cluster.KMeans(n_clusters=k)\n",
    "        # Afegim les dades\n",
    "        kmeans.fit(df)\n",
    "        # Obtenim SSE\n",
    "        sse.append(kmeans.inertia_)\n",
    "\n",
    "    if ax is not None:\n",
    "        return ax.plot(range(k_min, k_max), sse, marker='o')\n",
    "    else:\n",
    "        return plt.plot(range(k_min, k_max), sse, marker='o')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classificació d'empreses del domini .CAT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al puntCAT, el 10 de gener de 2020 hi havien registrats un total de 108.445 dominis. L'objectiu d'aquest document és descriure el procediment seguit per arribar a determinar quins d'aquests dominis pertanyen a una empresa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aquest procediment consta de diverses jerarquies:\n",
    "\n",
    "1. __Classificació segons la resposta__: Aquest primer nivell permet realitzar un filtratge ràpid de les URLs que no interessen analitzar. Per a fer-ho es realitza una petició GET al domini amb el mòdul de python `requests`. A partir d'aquí es considera:\n",
    "\n",
    "    * El servidor respon? Si no ho fa el domini queda descartat.\n",
    "    * El codi de resposta retornat és inferior a 400? Si no ho fa el domini queda descartat.\n",
    "    * El servidor redirecciona a un altre domini? Si ho fa el domini queda descartat ja que es vol realitzar únicament l'estudi dels dominis \".cat\". Cal tenir en compte que si el domini redirigeix a un altre dins del \".cat\" també es pot descartar perquè apareixerà en el llistat original.\n",
    "    \n",
    "2. __Classificació segons el contingut__: Una parts dels dominis que donguin resposta no resultaran interessants d'analitzar a priori perquè correspondran a pàgines web buides o _landing pages_ d'empreses de tercers que es dediquen a vendre els dominis. En aquest cas per accedir a la pàgina web es realitzarà utilitzant un navegador que suporti l'execució de Javascript (Google Chrome controlat amb Selenium). A partir d'aquí es considera:\n",
    "\n",
    "    * El navegador carrega la pàgina web? Si no ho fa el domini queda descartat.\n",
    "    * La pàgina web redirecciona a un altre domini utilitzant Javascript? Si ho fa el domini queda descartat ja que es vol realitzar únicament l'estudi dels dominis \".cat\". Cal tenir en compte, com abans, que si el domini redirigeix a un altre dins del \".cat\" també es pot descartar perquè apareixerà en el llistat original.\n",
    "    * Obtenir l'estructura de la pàgina web: mida de la pàgina, nombre de paraules, nombre de enllaços externs i interns i el nombre de vegades que apareixen un seguit de tags HTML: image, div, script, frame, style, meta i link. Amb aquestes dades utilitzar un model supervisat entrenat a partir de la classificació manual de 519 dominis que determini si la pàgina web presenta o no contingut. Si el model determina que no hi ha contingut el domini queda descartat.\n",
    "    \n",
    "3. __Classificació segons empresa__: En aquest punt es disposa del llistat de dominis que presenten una pàgina web dins del \".cat\" amb contingut. L'últim pas consisteix en classificar aquests dominis segons si pertanyen o no a una empresa. A partir d'aquí es considera:\n",
    "    * Obtenir diverses dades addicionals d'aquest domini:\n",
    "        * Buscar enllaços en la *landing page* referents a avís legal, galetes i privacitat, ocurrènces de les paraules registre mercantil i domicili fiscal, xarxes socials (twitter, facebook, linkedin, instagram and youtube), NIFs, correus electònics i telèfons.\n",
    "        * Per cada NIF trobat a la pàgina web buscar l'empresa associada amb l'*scraping* de [eInforma](https://www.einforma.com).\n",
    "        * Detectar les tecnologies utilitzades per cada pàgina web utilitzant [Wappalyzer](https://www.wappalyzer.com).\n",
    "        \n",
    "     A partir de totes aquests dades i la classificació manual de 370 pàgines web crear un model supervisat que ens retorni la probabilitat de cada pàgina de pertànyer a una empresa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tot aquest procés de captura de les dades ha estat realitzat en la totalitat dues vegades. Una primera des d'un Mac Pro connectat a la xarxa de la URV i una segona vegada amb un servidor remot proporcionat per la Fundació puntCAT mitjançant un script que es pot trobar en el següent [repositori](https://github.com/REPUBLIQUEM-CAT/domain_classifier)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neteja de les dades"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abans de començar amb la classificació és necessari obtenir les dades emmagatzemades a la base de dades relacional i netejar-les per així poder treballar còmodament amb elles.\n",
    "\n",
    "Primer de tot es realitza una _query_ que ens retornarà per cada domini tota la informació necessaria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT dc.domain, dc.codi_resposta, dc.redirecciona_a_req, dc.mida, dc.paraules, dc.internal_link, dc.external_link, dc.images, dc.div, dc.script, dc.frame, dc.style, dc.meta, dc.link, dc.contingut, dc.resposta_sel, dc.redirecciona_a_sel, dc.avis_legal, dc.privacitat, dc.cookies, dc.contacte, dc.registre_mercantil, dc.domicili_fiscal, dc.twitter, dc.facebook, dc.linkedin, dc.instagram, dc.youtube, dc.es_empresa, dc.builtwith, email_found.email, phone_found.phone, nif_found.nif, nif_found.nif_verificat, domini_puntcat.empresa_dirigit, domini_puntcat.es_empresa_manual, dc.lighthouse\n",
    "FROM domain_classification as dc\n",
    "LEFT JOIN (\n",
    "\tSELECT search, domini, COUNT(*) as email FROM domain_email GROUP BY search, domini\n",
    "\t) as email_found\n",
    "ON dc.search = email_found.search AND dc.domain = email_found.domini\n",
    "LEFT JOIN (\n",
    "\tSELECT search, domini, COUNT(*) as phone FROM domain_phone GROUP BY search, domini\n",
    "\t) as phone_found\n",
    "ON dc.search = phone_found.search AND dc.domain = phone_found.domini\n",
    "LEFT JOIN (\n",
    "SELECT COUNT(*) AS nif, SUM(CASE WHEN denominacio IS NULL THEN 0 ELSE 1 END) AS nif_verificat, domini, domain_nif.search\n",
    "\tFROM domain_nif\n",
    "\tLEFT JOIN empresa ON domain_nif.nif = empresa.nif\n",
    "\tWHERE domain_nif.search IN (SELECT search FROM (SELECT MAX(search) as search, domain FROM domain_classification GROUP BY domain) AS to_select)\n",
    "\tGROUP BY domini, domain_nif.search\n",
    ") as nif_found\n",
    "ON dc.search = nif_found.search AND dc.domain = nif_found.domini\n",
    "LEFT JOIN domini_puntcat ON domini_puntcat.domini = dc.domain\n",
    "WHERE dc.search IN (SELECT search FROM (SELECT MAX(search) as search, domain FROM domain_classification GROUP BY domain) AS to_select)\n",
    "\"\"\"\n",
    "# AND domini_puntcat.es_empresa_manual IS NOT NULL AND dc.response_url IS NOT NULL AND dc.codi_resposta = 200 AND dc.redirecciona_a_req IS NULL AND dc.contingut IS TRUE;\n",
    "# Fetch query\n",
    "contingut = pd.read_sql_query(query, conn)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es comprova que les dades s'hagin carregat correctament."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "contingut.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El nombre de files i columnes obtingudes de la _query_ són respectivament:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "contingut.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seguidament es llisten el nom de totes les columnes i es procedeix amb la neteja de les dades."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "contingut.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* __Columnes d'empresa__: La columna booleana corresponent a la variable classe `es_empresa_manual` serà separada del conjunt d'atributs. Addicionalment també ho serà la columna `empresa_dirigit` que són aquells dominis classificats manualment de manera dirigida. Finalment la columna que conté la probabilitat de pertànyer a una empresa `es_empresa` també serà separada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "es_empresa = contingut.loc[:, [\"es_empresa_manual\"]]\n",
    "es_empresa = es_empresa.applymap(lambda x: 1 if x is True else x)\n",
    "es_empresa = es_empresa.applymap(lambda x: 0 if x is False else x)\n",
    "\n",
    "empresa_dirigit = contingut.loc[:, [\"empresa_dirigit\"]]\n",
    "empresa_dirigit = empresa_dirigit.applymap(lambda x: 1 if x is True else 0)\n",
    "\n",
    "prob_empresa = contingut.loc[:, [\"es_empresa\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Les columnes de valors flotants `email`, `phone`, `nif`, `nif_verificat` seran convertides en binàries en funció de si tenen o no dades."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "epnn = contingut.loc[:, [\"email\", \"phone\", \"nif\", \"nif_verificat\"]]\n",
    "epnn = epnn.fillna(0)\n",
    "epnn = epnn.applymap(lambda x: 1 if x>0 else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Les tecnologies de la pàgina web presents a la columna `builtwith` seran separades per a crear un seguit de columnes binàries a partir d'aquesta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "for index, row in contingut.iterrows():\n",
    "    applications_list = {}\n",
    "    data = row[\"builtwith\"]\n",
    "    if data is not None and \"applications\" in data:\n",
    "            for application in data[\"applications\"]:\n",
    "                for category_number, category_name in application[\"categories\"].items():\n",
    "                    if category_name not in applications_list:\n",
    "                        applications_list[category_name] = []\n",
    "                    applications_list[category_name].append(application[\"name\"])\n",
    "    contingut.at[index, \"builtwith\"] = applications_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "group_tecnologies_cols = []\n",
    "group_tecnologies = contingut[[\"builtwith\"]].copy()\n",
    "\n",
    "for index, row in group_tecnologies.iterrows():\n",
    "    keys = list(row[\"builtwith\"].keys())\n",
    "    for key in keys:\n",
    "        if key not in group_tecnologies_cols:\n",
    "            group_tecnologies_cols.append(key)\n",
    "    \n",
    "for column in group_tecnologies_cols:\n",
    "    group_tecnologies[column] = 0\n",
    "\n",
    "for index, row in group_tecnologies.iterrows():\n",
    "    keys = list(row[\"builtwith\"].keys())\n",
    "    for key in keys:\n",
    "        group_tecnologies.loc[index, key] = 1\n",
    "    \n",
    "group_tecnologies = group_tecnologies.drop(columns=[\"builtwith\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Les columnes referents a l'estructura de la pàgina web seran normalitzades entre 0 i 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "estructura_cols = [\"mida\", \"paraules\", \"internal_link\", \"external_link\", \"images\", \"div\", \"script\", \"style\", \"meta\", \"link\"]\n",
    "estructura = contingut[estructura_cols]\n",
    "estructura = MinMaxScaler().fit_transform(estructura)\n",
    "estructura = pd.DataFrame(estructura, columns=estructura_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Les columnes referents al contingut de la pàgina web (avís legal, cookies, xarxes socials, etc) seran convertides també a binaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "contingut_object_cols = [\"avis_legal\", \"privacitat\", \"cookies\", \"contacte\", \"twitter\", \"facebook\", \"instagram\", \"linkedin\", \"youtube\"]\n",
    "contingut_object = contingut[contingut_object_cols]\n",
    "contingut_object = contingut_object.applymap(lambda x: 1 if x is not None else 0)\n",
    "\n",
    "\n",
    "contingut_bool_cols = ['registre_mercantil', 'domicili_fiscal']\n",
    "contingut_bool = contingut.loc[:, contingut_bool_cols]\n",
    "booleanDictionary = {True: 1, False: 0}\n",
    "\n",
    "for column in contingut_bool_cols:\n",
    "    contingut_bool[column] = contingut[column].map(booleanDictionary)\n",
    "#contingut_bool = contingut[contingut_bool_cols]\n",
    "#contingut_bool = contingut_bool.applymap(lambda x: 1 if True else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Els diversos paràmetres de les auditories que conté la columna `lightouse` seran separats:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def lighthouse_score(row):\n",
    "    data = row[\"lighthouse\"]\n",
    "    if data is None:\n",
    "        return None, None, None, None, None\n",
    "    pwa = data[\"categories\"][\"pwa\"][\"score\"]\n",
    "    seo = data[\"categories\"][\"seo\"][\"score\"]\n",
    "    best_practices = data[\"categories\"][\"best-practices\"][\"score\"]\n",
    "    accessibility = data[\"categories\"][\"accessibility\"][\"score\"]\n",
    "    performance = data[\"categories\"][\"performance\"][\"score\"]\n",
    "    \n",
    "    return pwa, seo, best_practices, accessibility, performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "scores = contingut.apply(lighthouse_score, axis=1, result_type=\"expand\")\n",
    "score_columns = [\"pwa\", \"seo\", \"best_practices\", \"accessibility\", \"performance\"]\n",
    "scores.columns = score_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "rows = []\n",
    "for i, row in contingut.iterrows():\n",
    "    audits = {\"domain\": row[\"domain\"]}\n",
    "    if row[\"lighthouse\"] is not None:\n",
    "        for key, value in row[\"lighthouse\"][\"audits\"].items():\n",
    "            audits[key] = value[\"score\"]\n",
    "        rows.append(audits)\n",
    "\n",
    "audits = json_normalize(rows)\n",
    "audits_cols = audits.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Altres columnes que no necessiten transformació."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "altres_cols = [\"domain\", \"codi_resposta\", \"redirecciona_a_req\", \"contingut\", \"resposta_sel\", \"redirecciona_a_sel\"]\n",
    "altres = contingut[altres_cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalment es junten totes les columnes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "clean = concat_frames([es_empresa, empresa_dirigit, prob_empresa, epnn, estructura, contingut_object, contingut_bool, altres, group_tecnologies, scores, audits])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "clean.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Addicionalment s'exporta la taula neta a un fitxer CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "clean.to_csv(\"empreses_lightohuse_only_manually_classified.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classificació segons la resposta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "clean = pd.read_csv(\"empreses_some_builtwith.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aquest primer nivell permet realitzar un filtratge ràpid de les URLs que no interessen analitzar. Per a fer-ho es realitza una petició GET al domini amb el mòdul de python `requests`.\n",
    "\n",
    "A partir d'aquí es determina si el servidor respon a la petició i si ho fa amb quin codi de resposta. En el següent gràfic es mostren els servidors que no han respost amb el `codi_resposta` -1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "clean.codi_resposta = clean.codi_resposta.fillna(-1)\n",
    "ax = clean.groupby(\"codi_resposta\").size().plot(kind='bar', figsize=(15,7), title=\"Codis resposta dels dominis\")\n",
    "add_value_labels(ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De tots aquests dominis seguiran en el llistat de posibles empreses aquells que hagin retornat un codi de resposta més petit de 400 i major o igual a 200. Els [codis de resposta](https://developer.mozilla.org/es/docs/Web/HTTP/Status) 3XX corresponen a redireccions i els 2XX a èxit mentre que els 4XX a un error del client i els 5XX a un error del serividor. Cal destacar el codi resposta 999 que és retornat usualment per Linkedin al realitzar peticions automatitzades a la seva pàgina web.\n",
    "\n",
    "Agregant aquestes condicions esmentades en el gràfic següent es mostren els dominis que segueixen en consideració. Addicionalment es proporciona una comparació entre la última execució (Juliol 2020)  i la primera execució (Febrer 2020) on es pot veure la pèrdua d'una mica més de 6.000 dominis. Aquest fet podria ser degut a la situació actual del COVID-19 i la cancel·lació dels serveis que mantenen el domini operatiu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1,2, figsize=(15,7))\n",
    "plt.suptitle(\"Codis resposta OK vs KO\")\n",
    "\n",
    "resposta_ok = clean[(clean.codi_resposta < 400) & (clean.codi_resposta > 0) ]\n",
    "resposta_ko = clean[(clean.codi_resposta > 400) | (clean.codi_resposta < 0) ]\n",
    "#classificacio_resposta = pd.DataFrame({\"resposta\": [\"resposta_ok\", \"resposta_ko\"], \"count\": [resposta_ok, resposta_ko]})\n",
    "classificacio_resposta = pd.DataFrame(data=[resposta_ok.shape[0], resposta_ko.shape[0]], index=[\"resposta_ok\", \"resposta_ko\"])\n",
    "classificacio_resposta.plot.bar(rot=0, title=\"Execució juliol 2020\", ax=ax1)\n",
    "add_value_labels(ax1)\n",
    "\n",
    "\n",
    "classificacio_old = pd.DataFrame(data=[84037, 24407], index=[\"resposta_ok\", \"resposta_ko\"])\n",
    "classificacio_old.plot.bar(rot=0, title=\"Execució febrer 2020\", ax=ax2)\n",
    "add_value_labels(ax2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EL següent filtratge de dominis ve determinat per les redireccions que aquests presenten. Com que únicament es volen estudiar els dominis \".cat\" tots aquells que presentin una redirecció seran automàticament descartats. Cal esmentar que aquells que presentin una redirecció a un altre domini \".cat\" també seran descartats perquè ja estaran implícits en el llistat original."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "sense_redirecció = resposta_ok[resposta_ok.redirecciona_a_req.isna()]\n",
    "amb_redirecció = resposta_ok[resposta_ok.redirecciona_a_req.isna() == False]\n",
    "classificacio_resposta = pd.DataFrame(data=[sense_redirecció.shape[0], amb_redirecció.shape[0]], index=[\"Sense redirecció\", \"Amb redirecció\"])\n",
    "ax = classificacio_resposta.plot.bar(rot=0, figsize=(15,7), title=\"Dominis sense redirecció VS amb redirecció\")\n",
    "add_value_labels(ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalment es mostren els 10 dominis amb més redireccions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "resposta_ok.groupby(\"redirecciona_a_req\").size().to_frame().sort_values(by=0, ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classificació segons el contingut"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El següent punt en l'anàlisi dels dominis serà determinar si aquests presenten suficient informació per a ser analitzats. Alguns d'aquests dominis seran propietat de tercers com Nominalia, XXXXXX o XXXX entre d'altres que es dediquen a la venda de dominis o bé seran únicament _landing pages_ en blanc o amb l'índex de fitxers presents en el servidor. Com és evident tots aquests dominis es descartaran perquè no presenten prou contingut rellevant per a ser analitzats. L'objectiu final d'aquest apartat serà la creació d'un model supervisat que determini si tenen o no contingut, per a fer-ho es capturaran diversos aspectes de la pàgina web com la mida de la pàgina, nombre de paraules, nombre de enllaços externs i interns i el nombre de vegades que apareixen un seguit de tags HTML com image, div, script, frame, style, meta o link.\n",
    "\n",
    "El fet és que per arribar a determinar de manera correcta aquests aspectes de la pàgina, aquesta ha de ser carregada per complet el que significa l'ús de Javascript. Per a procedir doncs s'accedirà a la pàgina web utilitzant un navegador que suporti l'execució de Javascript, que en aquest cas serà Google Chrome automatitzat amb [Selenium](https://selenium-python.readthedocs.io) mitjançant Python.\n",
    "\n",
    "\n",
    "Abans de procedir amb la creació del model, l'accés als dominis mitjançant Google Chrome pot suposar que alguns dominis no responguin o bé que redirigeixin a un altre mitjançant Javascript. Per aixó es torna a realitzar el mateix filtratge que en el primer apartat, i en aquest cas el primer nivell queda determinat per si el navegador és capaç de carregar la pàgina web."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "resposta_ok_sel = sense_redirecció[sense_redirecció.resposta_sel == True]\n",
    "resposta_ko_sel =  sense_redirecció[sense_redirecció.resposta_sel == False]\n",
    "classificacio_resposta = pd.DataFrame(data=[resposta_ok_sel.shape[0], resposta_ko_sel.shape[0]], index=[\"Resposta OK Selenium\", \"Resposta KO Selenium\"])\n",
    "ax = classificacio_resposta.plot.bar(rot=0, figsize=(15,7), title=\"Codis resposta Selenium OK vs KO\")\n",
    "add_value_labels(ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El següent punt és la redirecció a un altre domini."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sense_redirecció_sel = resposta_ok_sel[resposta_ok_sel.redirecciona_a_sel.isna()]\n",
    "amb_redirecció_sel = resposta_ok_sel[resposta_ok_sel.redirecciona_a_sel.isna() == False]\n",
    "classificacio_resposta = pd.DataFrame(data=[sense_redirecció_sel.shape[0], amb_redirecció_sel.shape[0]], index=[\"sense_redirecció_sel\", \"amb_redirecció_sel\"])\n",
    "ax = classificacio_resposta.plot.bar(rot=0, figsize=(15,7), title=\"Sense redirecció VS amb redirecció\")\n",
    "add_value_labels(ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Igual que en l'apartat anterior es mostren els 10 dominis més populars per a les redireccions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "resposta_ok_sel.groupby(\"redirecciona_a_sel\").size().to_frame().sort_values(by=0, ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En aquest punt gràcies a la utilització d'un navegador automatitzat s'han pogut capturar els següents aspectes de la pàgina web:\n",
    "* Mida.\n",
    "* Nombre de paraules.\n",
    "* Nombre d'enllaços interns.\n",
    "* Nombre d'enllaços externs\n",
    "* Nombre d'aparicions de cadascuna de les següents _tags_ HTML: image, div, script, frame, style, meta i link.\n",
    "\n",
    "Després de la classificació manual de 519 dominis amb/sense contingut es decideix aplicar el model `RandomForest`. La mostra va ser dividida 70/30 i es va etrar el model amb la generació de 500 arbres de decisió. Aquest model va ser validat amb el conjunt de test obtenint les mètriques que es mostren a continuació.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "metriques = pd.DataFrame(data=[92.9, 90.6, 5.4, 8, 86.9, 94.6], index=[\"accuracy\", \"f1_score\", \"fnr\", \"fpr\", \"precision\", \"recall\"])\n",
    "ax = metriques.plot.bar(rot=0, title=\"Mètriques RandomForest (%)\", figsize=(5, 6))\n",
    "add_value_labels(ax)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En aplicar el model a la totalitat de les dades es va obtenir la següent classificació:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1,2, figsize=(15,7))\n",
    "plt.suptitle(\"Amb contingut Selenium VS sense contingut Selenium\")\n",
    "\n",
    "amb_contingut = sense_redirecció_sel[sense_redirecció_sel.contingut == True]\n",
    "sense_contingut = sense_redirecció_sel[sense_redirecció_sel.contingut == False]\n",
    "classificacio_resposta = pd.DataFrame(data=[amb_contingut.shape[0], sense_contingut.shape[0]], index=[\"Amb contingut Selenium\", \"Sense contingut Selenium\"])\n",
    "classificacio_resposta.plot.bar(rot=0, title=\"Execució juliol 2020\", ax=ax1)\n",
    "add_value_labels(ax1)\n",
    "\n",
    "classificacio_old = pd.DataFrame(data=[34701, 19965], index=[\"Amb contingut Selenium\", \"Sense contingut Selenium\"])\n",
    "classificacio_old.plot.bar(rot=0, title=\"Execució febrer 2020\", ax=ax2)\n",
    "add_value_labels(ax2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com que el nombre de dominis sense contingut va ser bastant elevat i suposava un 36.5% de la totalitat dels dominis restants (54666) es va buscar una manera alternativa per determinar si un domini té o no contingut i contrastar-ho amb els resultats del model.\n",
    "El que es va decidir estudiar va ser la similitud entre els dominis, en el cas que hi hagin molts dominis que presentin la mateixa estructura interna (tags HTML) es podria dir que són el mateix domini. Un clar exemple són totes aquelles pàgines que retornen un HTML buit o la mateixa estructura de la pàgina per defecte d'un domini que està en venda.\n",
    "\n",
    "Per dir que dos dominis \"eren el mateix\" es va fixar el límit en més de tres dominis, és a dir, si 4 o més dominis s'agrupaven en la mateixa estructura es consideren dominis repetits, en cas contrari no.\n",
    "\n",
    "En comparar els resultats es va observar que:\n",
    "\n",
    "* En ambdós casos els dominis classificats sense contingut van ser 16.975.\n",
    "* 1.687 dominis van ser considerats sense contingut per la similitud entre dominis i amb contingut pel Random Forest.\n",
    "* 2.990 dominis van ser considerats amb contingut per la similitud entre dominis i sense contingut pel Random Forest.\n",
    "\n",
    "Veient doncs com amdós mètodes donaven resultats molt similars es va decidir donar per bo el model del Random Forest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classificació segons empresa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En aquest punt es disposa del llistat de dominis que presenten una pàgina web dins del \".cat\" amb contingut. L'últim pas consisteix en classificar aquests dominis segons si pertanyen o no a una empresa. A partir d'aquí es considera:\n",
    "* Obtenir diverses dades addicionals d'aquest domini:\n",
    "    * Buscar enllaços en la *landing page* referents a avís legal, galetes i privacitat, ocurrènces de les paraules registre mercantil i domicili fiscal, xarxes socials (twitter, facebook, linkedin, instagram and youtube), NIFs, correus electònics i telèfons.\n",
    "    * Per cada NIF trobat a la pàgina web buscar l'empresa associada amb l'*scraping* de [eInforma](https://www.einforma.com).\n",
    "    * Detectar les tecnologies utilitzades per cada pàgina web utilitzant [Wappalyzer](https://www.wappalyzer.com).\n",
    "        \n",
    "  A partir de totes aquests dades i la classificació manual de 479 pàgines web crear un model supervisat que ens retorni la probabilitat de cada pàgina de pertànyer a una empresa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "clean = resposta_ok_sel[resposta_ok_sel.es_empresa_manual.isna() == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "clean.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Per determinar si són o no empreses es disposen de tres grups de dades\n",
    "* Les obtingudes a partir d'analitzar el contingut de la pàgina web. En aquest cas totes les variables són binàries (1 o 0) en funció de si s'ha detectat la condició o no.\n",
    "    * Enllaç a avís legal, privacitat, galetes i contacte.\n",
    "    * Aparició de les paraules registre mercantil i domicili fiscal.\n",
    "    * Perfils de xarxes socials (Twitter, Facebook, Instagram, Youtube i Linkedin).\n",
    "    * Correu electrònic i número de telèfon.\n",
    "    * NIF i la seva corresponent verificació a [eInforma](https://www.einforma.com) (és a dir si hi ha una empresa registrada darrera del NIF).\n",
    "* Les obtingudes anteriorment en l'anàlisi de l'estructura de la web (si tenen o no contingut). En aquest cas els valors es troben normalitzats entre 0 i 1.\n",
    "    * Mida.\n",
    "    * Nombre de paraules.\n",
    "    * Nombre d'enllaços interns.\n",
    "    * Nombre d'enllaços externs\n",
    "    * Nombre d'aparicions de cadascuna de les següents _tags_ HTML: image, div, script, frame, style, meta i link.\n",
    "* Les obtingudes després d'analitzar les tecnologies utilitzades per cada pàgina web com pot ser l'´ús d'una plataforma de e-commerce, Google Analytics, SEO o CMS entre molts d'altres. En aquest cas les variables són binàries (1 o 0) en funció de si s'ha detectat la condició o no.\n",
    "\n",
    "Les columnes referents a cada grup es veuen a continuació."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "contingut_cols = ['registre_mercantil', 'domicili_fiscal', 'avis_legal', 'privacitat', 'cookies', 'contacte', 'twitter', 'facebook', 'linkedin', 'instagram', 'youtube', 'email', 'phone', 'nif', 'nif_verificat']\n",
    "estructura_cols = ['mida', 'paraules', 'internal_link', 'external_link', 'images', 'div', 'script', 'style', 'meta', 'link']\n",
    "group_tecnologies_cols = ['Analytics', 'Font scripts', 'Web frameworks', 'Web servers', 'Programming languages', 'Operating systems', 'Tag managers', 'JavaScript libraries', 'UI frameworks', 'CMS', 'Blogs', 'Widgets', 'Ecommerce', 'Captchas', 'Miscellaneous', 'Databases', 'Maps', 'Reverse proxies', 'SEO', 'PaaS', 'Mobile frameworks', 'Live chat', 'Video players', 'Editors', 'JavaScript graphics', 'JavaScript frameworks', 'Issue trackers', 'Hosting panels', 'CDN', 'Caching', 'Advertising', 'Page builders', 'Web server extensions', 'Static site generator', 'Comment systems', 'Payment processors', 'Marketing automation', 'Database managers', 'Photo galleries', 'Rich text editors', 'Webmail', 'LMS', 'Development', 'Message boards', 'Search engines', 'Network storage', 'DMS', 'Cryptominers', 'Wikis', 'Documentation tools']\n",
    "no_nul_audits_cols = ['no-vulnerable-libraries', 'js-libraries', 'maskable-icon', 'splash-screen', 'installable-manifest', 'no-document-write', 'notification-on-start', 'offline-start-url', 'password-inputs-can-be-pasted-into', 'uses-http2', 'uses-passive-event-listeners', 'meta-description', 'http-status-code', 'font-display', 'geolocation-on-start', 'external-anchors-use-rel-noopener', 'dom-size', 'charset', 'html-has-lang', 'uses-long-cache-ttl', 'total-byte-weight', 'render-blocking-resources', 'unminified-css', 'unminified-javascript', 'unused-css-rules', 'aria-hidden-body', 'uses-webp-images', 'uses-optimized-images', 'uses-text-compression', 'uses-responsive-images', 'efficient-animated-content', 'appcache-manifest', 'doctype', 'uses-rel-preconnect', 'document-title', 'uses-rel-preload', 'mainthread-work-breakdown', 'viewport', 'speed-index', 'plugins', 'hreflang', 'works-offline', 'bootup-time', 'max-potential-fid', 'cumulative-layout-shift', 'errors-in-console', 'server-response-time', 'first-contentful-paint', 'largest-contentful-paint', 'tap-targets', 'is-crawlable', 'apple-touch-icon', 'themed-omnibox', 'content-width', 'image-aspect-ratio', 'image-size-responsive', 'is-on-https', 'link-text', 'deprecations', 'service-worker']\n",
    "score_cols = [\"pwa\", \"seo\", \"best_practices\", \"accessibility\", \"performance\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seguidament es procedeix a visualitzar cadascun dels grups de dades.\n",
    "\n",
    "* __Contingut de la pàgina web__:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, ax_temp = plt.subplots(4,4, figsize=(20, 20))\n",
    "ax_list = []\n",
    "for i in ax_temp:\n",
    "    for j in i:\n",
    "        ax_list.append(j)\n",
    "        \n",
    "for col, ax in zip(contingut_cols, ax_list):\n",
    "    data = pd.concat([clean[[col]], clean[[\"es_empresa_manual\"]]], axis=1)\n",
    "    mosaic(data, [col, \"es_empresa_manual\"], ax=ax)\n",
    "    ax.set_xlabel(xlabel=col)\n",
    "    ax.set_ylabel(ylabel=\"Empresa\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Per cada columna es realitza un test d'independència de chi quadrat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "p_value = chi2(clean[contingut_cols], clean.es_empresa_manual)[1]\n",
    "pd.DataFrame({\"cols\": contingut_cols, \"p_value\": p_value}).sort_values(by='p_value').query(\"p_value < 0.05\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En aquest cas es pot obsevar com tots els p-valors són inferiors a 0.05 i per tant es descarta la hipòtesi nul·la i es pot dir que hi ha una relació entre ser una empresa i cadascuna de les columnes. Addicionalment amb els gràfics també es pot apreciar la importància de totes les variables en funció de si són o no empreses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* __Estructura de la pàgina web__:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "fig, ax_temp = plt.subplots(5,2, figsize=(20, 30))\n",
    "ax_list = []\n",
    "for i in ax_temp:\n",
    "    for j in i:\n",
    "        ax_list.append(j)\n",
    "        \n",
    "for col, ax in zip(estructura_cols, ax_list):\n",
    "    plot = hist_groupby(clean, col, \"es_empresa_manual\", ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En aquest cas a simple vista no s'aprecia una gran diferència en la distribució de les variables. Tot i així les que visualment mostren més diferència entre grups són mida, paraules i images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* __Tecnologies de la pàgina web__:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "fig, ax_temp = plt.subplots(13,4, figsize=(20, 50))\n",
    "ax_list = []\n",
    "for i in ax_temp:\n",
    "    for j in i:\n",
    "        ax_list.append(j)\n",
    "        \n",
    "for col, ax in zip(group_tecnologies_cols, ax_list):\n",
    "    data = pd.concat([clean[[col]], clean.es_empresa_manual], axis=1)\n",
    "    mosaic(data, [col, \"es_empresa_manual\"], ax=ax)\n",
    "    ax.set_xlabel(xlabel=col)\n",
    "    ax.set_ylabel(ylabel=\"Empresa\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Audtories:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Per cada columna es realitza un test d'independència de chi quadrat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "p_value = chi2(clean[group_tecnologies_cols], clean.es_empresa_manual)[1]\n",
    "tecnologies_chi2 = pd.DataFrame({\"cols\": group_tecnologies_cols, \"p_value\": p_value})\n",
    "tecnologies_chi2.sort_values(by='p_value').query(\"p_value < 0.05\").to_latex(\"teconologies.text\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En aquest cas es pot obsevar com 10 dels p-valors són inferiors a 0.05 i per tant es descarta la hipòtesi nul·la i es pot dir que hi ha una relació entre ser una empresa i aquestes columnes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "fig, ax_temp = plt.subplots(15,4, figsize=(20, 50))\n",
    "ax_list = []\n",
    "for i in ax_temp:\n",
    "    for j in i:\n",
    "        ax_list.append(j)\n",
    "        \n",
    "for col, ax in zip(no_nul_audits_cols, ax_list):\n",
    "    data = pd.concat([clean[[col]], clean.es_empresa_manual], axis=1)\n",
    "    mosaic(data, [col, \"es_empresa_manual\"], ax=ax)\n",
    "    ax.set_xlabel(xlabel=col)\n",
    "    ax.set_ylabel(ylabel=\"Empresa\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "p_value = chi2(clean[no_nul_audits_cols], clean.es_empresa_manual)[1]\n",
    "audits_chi2 = pd.DataFrame({\"cols\": no_nul_audits_cols, \"p_value\": p_value})\n",
    "audits_chi2.sort_values(by='p_value').query(\"p_value < 0.05\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "clean[no_nul_audits_cols + [\"domain\", \"es_empresa_manual\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "Una vegada visualitzades cadascuna de les columnes es procedirà a la creació del model. A priori s'estudiaran dos models supervisats `SVM` i `RandomForest`, i com afecta la inclusió o no d'algunes variables al model (columnes contingut, estructura i tecnologies).\n",
    "\n",
    "El procediment per a l'estudi serà el següent:\n",
    "\n",
    "* Seleccionar les columnes pertinents i dividir el conjunt de dades en entrenament i test 70/30.\n",
    "* Utilitzar 5-fold cross-validation sobre el conjunt d'entrenament (70%) per realitzar el _tunning_ dels paràmetres i estimar el comportament de cada model (SVM i RandomForest). La literatura científica sol assignar de manera arbitrària el valor de 5 o 10 a k. En aquest cas al no tenir una mostra de dades molt gran es decideix optar pel valor 5.\n",
    "* Validar el model amb el conjunt de test (validació) mai vist per aquest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Per a SVM es provaran els tres kernels: linear, radial basis function (rbf) i sigmoid. Addicionalment els hiperparàmetres C i gamma.\n",
    "* __C__: paràmetre de regularització. Com més gran és C més petit és el marge, i com més petit C més gran el marge.\n",
    "* __gamma__: Defineix com de lluny arriba la influència d'una observació d'entrenament. Com més petit el valor més lluny arriba la influència i com més gran menys lluny."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "models_svm = {\n",
    "    'SVC': SVC()\n",
    "}\n",
    "\n",
    "params_svm = {\n",
    "    'SVC': [\n",
    "        {'kernel': ['linear'], 'C': [0.01, 0.1, 1, 10, 50, 100]},\n",
    "        {'kernel': ['rbf'], 'C': [0.01, 0.1, 1, 10, 50, 100], 'gamma': [0.001, 0.0001, 0.01, 0.1]},\n",
    "        {'kernel': ['sigmoid'], 'C': [0.01, 0.1, 1, 10, 50, 100], 'gamma': [0.001, 0.0001, 0.01, 0.1]}\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Per a Random Forest es testejaran els hiperparàmmetres nombre d'estimadors i màxima profunditat:\n",
    "* __n_estimators__: Nombre d'arbres de classificació a crear.\n",
    "* __max_depth__: Màxima profunditat dels arbres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "models_rfc = {\n",
    "    'RandomForestClassifier': RandomForestClassifier(),\n",
    "}\n",
    "\n",
    "params_rfc = {\n",
    "    'RandomForestClassifier': { \n",
    "        'n_estimators': [16, 32, 64, 100, 200, 500], \n",
    "        'max_depth': [2,4,8, 10, 20, 50, 100] },\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Per mantenir el conjunt d'entrenament i test igual al llarg del document es dividirà una vegada a l'inici la mostra de les dades."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Seleccionem totes les columnes possibles\n",
    "all_cols = contingut_cols + tecnologies_chi2.query(\"p_value < 0.05\").cols.values.tolist() + [\"mida\", \"paraules\", \"images\"]\n",
    "# Dividim 70/30\n",
    "X_train, X_test, y_train, y_test = train_test_split(clean, clean.es_empresa_manual, test_size=0.3)\n",
    "# Retornem els noms a les columnes\n",
    "X_train = pd.DataFrame(data=X_train, columns=clean.columns)\n",
    "X_test = pd.DataFrame(data=X_test, columns=clean.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models utilitzant les columnes de \"contingut\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En aquest cas s'estudia únicament com es comporten les columnes \"contingut\", obtingudes de l'scraping genèric de la pàgina web."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apliquem 5-fold cross-validation sobre el conjunt d'entrenament i visualitzem quins presenten el millor comportament. S'ordenen els resultats basats en la precisió mitjana obtinguda."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "helper1 = EstimatorSelectionHelper(models_svm, params_svm, scoring=[\"accuracy\"])\n",
    "helper1.fit(X_train[contingut_cols], y_train, n_jobs=2)\n",
    "\n",
    "scores = helper1.score_summary()\n",
    "scores.sort_values(by=\"mean_score_accuracy\", ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualitzem el comportament dels hiperparàmetres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(20,5))\n",
    "ax1.set(title=\"SVM rbf kernel\")\n",
    "helper1.search_plot(scores.query(\"estimator == 'SVC' and kernel == 'rbf'\"), \"mean_score_accuracy\", \"C\", \"gamma\", ax=ax1)\n",
    "ax2.set(title=\"SVM linear kernel\")\n",
    "helper1.search_plot(scores.query(\"estimator == 'SVC' and kernel == 'linear'\"), \"mean_score_accuracy\", \"C\", \"gamma\", ax=ax2)\n",
    "ax3.set(title=\"SVM sigmoid kernel\")\n",
    "helper1.search_plot(scores.query(\"estimator == 'SVC' and kernel == 'sigmoid'\"), \"mean_score_accuracy\", \"C\", \"gamma\", ax=ax3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Els dos kernels més afectats pels hiperparàmetres són rbf i sigmoid ambdos amb comportaments idèntics. Per a valors de gamma molt petits la precisió decreix i aquesta es contraresta amb valors alts de C. A mesura que s'incrementa gamma i es decrementa C la precisió mitjana es manté molt estable (80%-85%).\n",
    "\n",
    "Finalment s'entrena el model amb el conjunt d'entrenament, i els paràmetres que han obtingut millor resultat. En aquest cas ens quedem amb el kernel sigmoid amb C=50 i gamma=0.001. En aquest cas la precisió mínima és de les més elevades i la precisió màximes també."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "svm_c = SVC(C=50, gamma=0.001, kernel='sigmoid', probability=True)\n",
    "svm_c.fit(X_train[contingut_cols], y_train)\n",
    "svm_c.score(X_test[contingut_cols], y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Després de diverses execucions cal dir que SVM presenta en tot moments uns resultats bastant estables amb precisions d'entre el 83% i el 86%. A més, els hiperparàmetres escollits es repeteixen independentment del split realitzat d'entrenament i test.\n",
    "\n",
    "Addicionalment s'estudiarà la distribució de la predicció de la probabilitat de ser una empresa i la matriu de confusió associada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "predicted_c = pd.DataFrame(data={\"predicted_empresa\": svm_c.predict_proba(X_test[contingut_cols])[:, 1], \"es_empresa\": y_test})\n",
    "ax = sns.FacetGrid(predicted_c, hue=\"es_empresa\", height=5).map(sns.distplot, \"predicted_empresa\", bins=20, kde=False).add_legend()\n",
    "ax.set(title=\"Distribució de la predicció de probabilitat de ser empresa\")\n",
    "ax.fig.axes[0].axvline(0.5, color=\"red\", linestyle=\"--\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "plot_confusion_matrix(svm_c, X_test[contingut_cols], y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Després d'examinar els falsos positius, falsos negatius i la distribució de la predicció d'empreses podem dir que:\n",
    "* El model és capaç d'identificar correctament aquells dominis que __clarament__ són d'una empresa. És a dir, aquelles pàgines web ben construides amb la majoria de la informació rellevant que aquestes poden tenir (telèfon, correu elèctronic, nif, enllaços d'interès).\n",
    "* Una gran quantitat dels falsos negatius són d'aquells dominis que pertanyen a una empresa però basant-nos en els paràmetres extrets, les dades són nules o pràcticament nules i per tant el model no pot determinar que es tracten d'empresa. Recordem que una gran quantitat dels verdaders negatius presenten una probabilitat d'entre el 0% i el 20% que pertanyen als dominis dels quals els paràmetres trobats són practicament nuls.\n",
    "* Evidentment trobem una zona d'incertesa entre el 40% i el 60% on nosaltres personalment podrem posar la barrera de tall on creiem més convenient. És a dir, quedar-nos com a empreses aquelles observacions que tenen una probabilitat major del 60% decrementant així els falsos positius (a costa dels falsos negatius).\n",
    "* La zona més preocupant es troba en aquelles observacions que no són empreses però l'algorisme determina amb una probabilitat d'entre el 80% que si que ho són. Aquest fet és degut a la alta importància que li assigna el model a les variables `email` i `phone` que de manera individual assignen una probabilitat del 38.6% i 52% respectivament i conjuntament la fan pujar al 78.61. Els 12 falsos positius del model es troben tots aquí.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apliquem 5-fold cross-validation sobre el conjunt d'entrenament i visualitzem quins presenten el millor comportament. S'ordenen els resultats basats en la precisió mitjana obtinguda."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "helper1 = EstimatorSelectionHelper(models_rfc, params_rfc, scoring=[\"accuracy\", \"f1\"])\n",
    "helper1.fit(X_train[contingut_cols], y_train, n_jobs=2)\n",
    "\n",
    "scores = helper1.score_summary()\n",
    "scores.sort_values(by=\"mean_score_accuracy\", ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualitzem el comportament dels hiperparàmetres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "helper1.search_plot(scores.query(\"estimator == 'RandomForestClassifier'\"), \"mean_score_accuracy\", \"n_estimators\", \"max_depth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrenem el model amb els hiperparàmetres escollits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "rfc_c = RandomForestClassifier(n_estimators=100, max_depth=8)\n",
    "rfc_c.fit(X_train[contingut_cols], y_train)\n",
    "rfc_c.score(X_test[contingut_cols], y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En aquest cas el model Random Forest té un comportament molt similar al SVM creat anteriorment amb precisions igual d'entre el 83 i 86%.\n",
    "\n",
    "Com abans, estudiem la distribució i la matriu de confusió."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "predicted_rfc_c = pd.DataFrame(data={\"predicted_empresa\": rfc_c.predict_proba(X_test[contingut_cols])[:, 1], \"es_empresa\": y_test})\n",
    "ax = sns.FacetGrid(predicted_rfc_c, hue=\"es_empresa\", height=5).map(sns.distplot, \"predicted_empresa\", bins=20, kde=False).add_legend()\n",
    "ax.set(title=\"Distribució de la predicció de probabilitat de ser empresa\")\n",
    "ax.fig.axes[0].axvline(0.5, color=\"red\", linestyle=\"--\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "plot_confusion_matrix(rfc_c, X_test[contingut_cols], y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com es pot observar en el gràfic de distribució i en la matriu de confusió el comportament és gairebé idèntic al SVM. Pel que fa als falsos positius els 12 dels 13 dominis classificats incorrectament coincideixen amb els del SVM.\n",
    "\n",
    "Vist doncs el comportament gairebé idèntic dels models i el gran biaix que suposen les variables `phone` i `email` es seguirà amb les pautes incialmet creades: estudiar com varia el model amb la inclusió o no d'algunes variables. Com s'espera que el model no variï significativament es realitzaran els mateixos passos que els realitzats en aquest apartat i es comentaran els resultats en l'apartat [1.4.6 - Conclusions models](#conclusions_model)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models utilitzant contingut i estructura"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En aquest cas s'estudia únicament com es comporten les columnes \"contingut\" i \"estructra\" més significatives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "ce_cols = contingut_cols + [\"mida\", \"paraules\", \"images\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apliquem 5-fold cross-validation sobre el conjunt d'entrenament i visualitzem quins presenten el millor comportament. S'ordenen els resultats basats en la precisió mitjana obtinguda.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "helper1 = EstimatorSelectionHelper(models_svm, params_svm, scoring=[\"accuracy\"])\n",
    "helper1.fit(X_train[ce_cols], y_train, n_jobs=2)\n",
    "\n",
    "scores = helper1.score_summary()\n",
    "scores.sort_values(by=\"mean_score_accuracy\", ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualitzem el comportament dels hiperparàmetres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(20,5))\n",
    "ax1.set(title=\"SVM amb kernel rbf\")\n",
    "helper1.search_plot(scores.query(\"estimator == 'SVC' and kernel == 'rbf'\"), \"mean_score_accuracy\", \"C\", \"gamma\", ax=ax1)\n",
    "ax1.set(title=\"SVM amb kernel linear\")\n",
    "helper1.search_plot(scores.query(\"estimator == 'SVC' and kernel == 'linear'\"), \"mean_score_accuracy\", \"C\", \"gamma\", ax=ax2)\n",
    "ax1.set(title=\"SVM amb kernel sigmoid\")\n",
    "helper1.search_plot(scores.query(\"estimator == 'SVC' and kernel == 'sigmoid'\"), \"mean_score_accuracy\", \"C\", \"gamma\", ax=ax3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrenem el model amb els hiperparàmetres escollits.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "svm_ce = SVC(C=50, gamma=0.01, kernel='sigmoid')\n",
    "svm_ce.fit(X_train[ce_cols], y_train)\n",
    "svm_ce.score(X_test[ce_cols], y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apliquem 5-fold cross-validation sobre el conjunt d'entrenament i visualitzem quins presenten el millor comportament. S'ordenen els resultats basats en la precisió mitjana obtinguda.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "helper1 = EstimatorSelectionHelper(models_rfc, params_rfc, scoring=[\"accuracy\"])\n",
    "helper1.fit(X_train[ce_cols], y_train, n_jobs=2)\n",
    "scores = helper1.score_summary()\n",
    "scores.sort_values(by=\"mean_score_accuracy\", ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualitzem el comportament dels hiperparàmetres.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "helper1.search_plot(scores.query(\"estimator == 'RandomForestClassifier'\"), \"mean_score_accuracy\", \"n_estimators\", \"max_depth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrenem el model amb els hiperparàmetres escollits.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier(n_estimators=32, max_depth=8)\n",
    "rfc.fit(X_train[ce_cols], y_train)\n",
    "rfc.score(X_test[ce_cols], y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models utilitzant contingut i tecnologies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En aquest cas s'estudia únicament com es comporten les columnes \"contingut\" i \"tecnologies\".\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "ct_cols = contingut_cols + tecnologies_chi2.query(\"p_value < 0.05\").cols.values.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apliquem 5-fold cross-validation sobre el conjunt d'entrenament i visualitzem quins presenten el millor comportament. S'ordenen els resultats basats en la precisió mitjana obtinguda.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "helper1 = EstimatorSelectionHelper(models_svm, params_svm, scoring=[\"accuracy\"])\n",
    "helper1.fit(X_train[ct_cols], y_train, n_jobs=2)\n",
    "\n",
    "scores = helper1.score_summary()\n",
    "scores.sort_values(by=\"mean_score_accuracy\", ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualitzem el comportament dels hiperparàmetres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(20,5))\n",
    "ax1.set(title=\"SVM amb kernel rbf\")\n",
    "helper1.search_plot(scores.query(\"estimator == 'SVC' and kernel == 'rbf'\"), \"mean_score_accuracy\", \"C\", \"gamma\", ax=ax1)\n",
    "ax1.set(title=\"SVM amb kernel linear\")\n",
    "helper1.search_plot(scores.query(\"estimator == 'SVC' and kernel == 'linear'\"), \"mean_score_accuracy\", \"C\", \"gamma\", ax=ax2)\n",
    "ax1.set(title=\"SVM amb kernel sigmoid\")\n",
    "helper1.search_plot(scores.query(\"estimator == 'SVC' and kernel == 'sigmoid'\"), \"mean_score_accuracy\", \"C\", \"gamma\", ax=ax3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrenem el model amb els hiperparàmetres escollits.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "svm = SVC(C=1, gamma=0.1, kernel='rbf')\n",
    "svm.fit(X_train[ct_cols], y_train)\n",
    "svm.score(X_test[ct_cols], y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apliquem 5-fold cross-validation sobre el conjunt d'entrenament i visualitzem quins presenten el millor comportament. S'ordenen els resultats basats en la precisió mitjana obtinguda."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "helper1 = EstimatorSelectionHelper(models_rfc, params_rfc, scoring=[\"accuracy\"])\n",
    "helper1.fit(X_train[ct_cols], y_train, n_jobs=2)\n",
    "scores = helper1.score_summary()\n",
    "scores.sort_values(by=\"mean_score_accuracy\", ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualitzem el comportament dels hiperparàmetres.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "helper1.search_plot(scores.query(\"estimator == 'RandomForestClassifier'\"), \"mean_score_accuracy\", \"n_estimators\", \"max_depth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrenem el model amb els hiperparàmetres escollits.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier(n_estimators=100, max_depth=2)\n",
    "rfc.fit(X_train[ct_cols], y_train)\n",
    "rfc.score(X_test[ct_cols], y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models utilitzant contingut, estructura i tecnologies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En aquest cas s'estudia amb el conjunt de les columnes estudiades fins ara.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "cet_cols = contingut_cols + tecnologies_chi2.query(\"p_value < 0.05\").cols.values.tolist() + [\"mida\", \"paraules\", \"images\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apliquem 5-fold cross-validation sobre el conjunt d'entrenament i visualitzem quins presenten el millor comportament. S'ordenen els resultats basats en la precisió mitjana obtinguda."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "helper1 = EstimatorSelectionHelper(models_svm, params_svm, scoring=[\"accuracy\"])\n",
    "helper1.fit(X_train[cet_cols], y_train, n_jobs=2)\n",
    "\n",
    "scores = helper1.score_summary()\n",
    "scores.sort_values(by=\"mean_score_accuracy\", ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualitzem el comportament dels hiperparàmetres.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(20,5))\n",
    "ax1.set(title=\"SVM amb kernel rbf\")\n",
    "helper1.search_plot(scores.query(\"estimator == 'SVC' and kernel == 'rbf'\"), \"mean_score_accuracy\", \"C\", \"gamma\", ax=ax1)\n",
    "ax1.set(title=\"SVM amb kernel linear\")\n",
    "helper1.search_plot(scores.query(\"estimator == 'SVC' and kernel == 'linear'\"), \"mean_score_accuracy\", \"C\", \"gamma\", ax=ax2)\n",
    "ax1.set(title=\"SVM amb kernel sigmoid\")\n",
    "helper1.search_plot(scores.query(\"estimator == 'SVC' and kernel == 'sigmoid'\"), \"mean_score_accuracy\", \"C\", \"gamma\", ax=ax3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrenem el model amb els hiperparàmetres escollits.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "svm = SVC(C=50, gamma=0.001, kernel='sigmoid')\n",
    "svm.fit(X_train[cet_cols], y_train)\n",
    "svm.score(X_test[cet_cols], y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apliquem 5-fold cross-validation sobre el conjunt d'entrenament i visualitzem quins presenten el millor comportament. S'ordenen els resultats basats en la precisió mitjana obtinguda."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "helper1 = EstimatorSelectionHelper(models_rfc, params_rfc, scoring=[\"accuracy\", \"f1\"])\n",
    "helper1.fit(X_train_cet, y_train_cet, n_jobs=2)\n",
    "scores = helper1.score_summary()\n",
    "scores.sort_values(by=\"mean_score_accuracy\", ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualitzem el comportament dels hiperparàmetres.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "helper1.search_plot(scores.query(\"estimator == 'RandomForestClassifier'\"), \"mean_score_accuracy\", \"n_estimators\", \"max_depth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrenem el model amb els hiperparàmetres escollits.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier(n_estimators=100, max_depth=8)\n",
    "rfc.fit(X_train_cet, y_train_cet)\n",
    "rfc.score(X_test_cet, y_test_cet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusions models<a id='conclusions_model'></a>\n",
    "\n",
    "Després d'haver vist com es comporten els models segons si a més de les columnes de \"contingut\" hi afegim l'estructura de la pàgina web o les tecnologies que aquesta utilitza podem determinar que aquestes variables extra no afecten de manera significativa al model. És més en la majoria dels casos les observacions classificades de manera incorrecta són sempre les mateixes:\n",
    "* Falsos negatius: pàgines web d'empreses però que tenen poca informació i amb els paràmetres extrets de la pàgina web no es poden diferenciar de les que no són empresa.\n",
    "* Falsos positius: pàgines web que no són d'empreses pero hi apareixen telèfons i correus electrònics. Recordem que aquestes dues variables juntes fan pujar entorn al 80% la probabilitat de ser empresa segons el model.\n",
    "\n",
    "Està clar doncs, que amb les dades extretes fins ara dels dominis no és possible obtenir un model superior. El problema rau doncs, com ja s'ha explicat, en pàgines web de no empreses que contenen la informació que nosaltres a priori haviem decidit rellevant per determinar que eren una empresa. Arribata a aquest punt podem:\n",
    "* Acceptar el model creat amb les dades actuals.\n",
    "* Obtenir una mostra més gran de dades. Encara que una mostra major pugui millorar lleugerament el model seguim tenint el problema dels falsos positius perquè les dades són les mateixes.\n",
    "* Afegir noves dades al model:\n",
    "   * Anàlisi NLP.\n",
    "   * Obtenir mètriques de la pàgina web utilitzant [Lighthouse](https://github.com/GoogleChrome/lighthouse). Aquest framework open-source de Google realitza anàlisi de SEO, Accessibilitat o rendiment entre d'altres a les pàgines web. Pot ser un bon enfocament per incrementar les dades encara que pot passar el mateix que amb les tecnologies utilitzades per una pàgina web: que resultin insignificants. De totes maneres cal tenir en compte que Lightouse és una proposta ja realitzada per extreure més indicadors del REPUBLIQUEM.CAT, i que per tant si s'acaba implementant s'hauran d'extreure igualment aquestes dades.\n",
    "\n",
    "De moment, s'agafa el model SVM creat inicialment amb kernel `sigmoid`, `C=50` i `gamma=0.001` i el procedim a aplicar al conjunt total dels dominis i visualitzar-ne els resultats.\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1,2, figsize=(5,10))\n",
    "probabilitat = svm_c.predict_proba(amb_contingut[contingut_cols])[:, 1]\n",
    "classificacio = svm_c.predict(amb_contingut[contingut_cols])\n",
    "\n",
    "final = pd.DataFrame({\"probabilitat\": probabilitat, \"classificacio\": classificacio})\n",
    "\n",
    "final.groupby(\"classificacio\").size().plot(kind='bar', figsize=(15,7), title=\"Classificació final\", ax=ax2)\n",
    "add_value_labels(ax2)\n",
    "sns.distplot(final.probabilitat, bins=20, ax=ax1, kde=False)\n",
    "ax1.axvline(0.5, color=\"red\", linestyle=\"--\")\n",
    "ax1.set(title=\"Disitrubció probabilitat de ser empresa\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1,2, figsize=(5,10))\n",
    "probabilitat = svm_c.predict_proba(amb_contingut[contingut_cols])[:, 1]\n",
    "classificacio = svm_c.predict(amb_contingut[contingut_cols])\n",
    "\n",
    "final = pd.DataFrame({\"probabilitat\": probabilitat, \"classificacio\": classificacio})\n",
    "\n",
    "final.groupby(\"classificacio\").size().plot(kind='bar', figsize=(15,7), title=\"Classificació final\", ax=ax2)\n",
    "add_value_labels(ax2)\n",
    "sns.distplot(final.probabilitat, bins=20, ax=ax1, kde=False)\n",
    "ax1.axvline(0.5, color=\"red\", linestyle=\"--\")\n",
    "ax1.set(title=\"Disitrubció probabilitat de ser empresa\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reducció de dimensionalitat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abans d'acabar la classificació dels dominis es realitzarà un últim anàlisi a partir de la reducció de dimensionalitat utilitzant PCA i un enfocament no supervisat amb Kmeans.\n",
    "\n",
    "Primer de tot apliquem PCA al conjunt d'entrenament."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "fig3 = plt.figure(constrained_layout=True, figsize=(12, 9))\n",
    "gs = fig3.add_gridspec(3, 3)\n",
    "ax1 = fig3.add_subplot(gs[0:2, 0:2], projection='3d')\n",
    "ax2 = fig3.add_subplot(gs[0:2, 2])\n",
    "ax3 = fig3.add_subplot(gs[2, 0])\n",
    "ax4 = fig3.add_subplot(gs[2, 1])\n",
    "ax5 = fig3.add_subplot(gs[2, 2])\n",
    "\n",
    "pca_c = PCAw()\n",
    "dominis_pca_c = pca_c.fit_transform(X_train[contingut_cols])\n",
    "ax1.scatter(xs=dominis_pca_c[:, 0], ys=dominis_pca_c[:, 1], zs=dominis_pca_c[:, 2], c=y_train)\n",
    "pca_c.variance_plot(ax=ax2)\n",
    "pca_c.plot_contribution(0, columns=contingut_cols, ax=ax3)\n",
    "pca_c.plot_contribution(1, columns=contingut_cols, ax=ax4)\n",
    "pca_c.plot_contribution(2, columns=contingut_cols, ax=ax5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Addicionalment creem una visualització interactiva en 3D afegint els *eigenvectors*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "scale = 2\n",
    "no_empresa = go.Scatter3d(\n",
    "    x=dominis_pca_c[y_train == 0,0],\n",
    "    y = dominis_pca_c[y_train == 0,1],\n",
    "    z = dominis_pca_c[y_train == 0,2],\n",
    "    mode='markers',\n",
    "    name=\"No empresa\",\n",
    "    hoverinfo='none',\n",
    "    marker=dict(\n",
    "        size=4,      \n",
    "        opacity=1\n",
    "    )\n",
    ")\n",
    "\n",
    "empresa = go.Scatter3d(\n",
    "    x=dominis_pca_c[y_train == 1,0],\n",
    "    y = dominis_pca_c[y_train == 1,1],\n",
    "    z = dominis_pca_c[y_train == 1,2],\n",
    "    mode='markers',\n",
    "    name=\"No empresa\",\n",
    "    hoverinfo='none',\n",
    "    marker=dict(\n",
    "        size=4,             \n",
    "        opacity=1\n",
    "    )\n",
    ")\n",
    "\n",
    "arrows = []\n",
    "for i, col in enumerate(contingut_cols):\n",
    "    dc_1 = go.Scatter3d( x = [0,pca_c.components_.T[i][0] * scale],\n",
    "                     y = [0,pca_c.components_.T[i][1] * scale],\n",
    "                     z = [0,pca_c.components_.T[i][2] * scale],\n",
    "                     marker = dict( size = 3,\n",
    "                                    color = \"rgb(84,48,5)\"),\n",
    "                     line = dict(color='green',\n",
    "                                width = 6),\n",
    "                     name = col\n",
    "                     )\n",
    "    arrows.append(dc_1)\n",
    "\n",
    "data = [no_empresa, empresa] + arrows\n",
    "layout = go.Layout(\n",
    ")\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Després d'aplicar PCA i visualitzar els tres primers components principals podem veure, com ja haviem determinat amb els altres models, que aquells dominis que realment són empresa són molt fàcils de classificar. A més aquells que no ho són també s'agrupen, encara que no tant clarament com els que si.\n",
    "És fàcil veure com els eigenvectors formen tres grups diferents:\n",
    "* Un per les xarxes socials: facebook, twitter, instagra, youtube i linkedin.\n",
    "* El grup amb més influència: phone, telèfon i enllaç a contacte. Aquest fet és un clar indicador de que molts telèfons de contacts i correus electòrnics es troben en la pestanya de contacte.\n",
    "* La resta de les dades com nif, enllaços avis legal, privacitat i cookies o els mots registre mercantil i domicili fiscal.\n",
    "\n",
    "A partir d'aquesta visualització procedim a aplicar l'algorisme K-means. Primer de tot decidim el millor valor de K mitjnçant dos mètodes: la silueta i el mètode del colze. Utilitzarem fins el component principal 11 on tenim el 95% de la variància acumulada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1,2, figsize=(20,5))\n",
    "ax1.set(title=\"Silhouette method\")\n",
    "plot_silhouette_method(dominis_pca_c[:, 0:11], ax=ax1)\n",
    "ax2.set(title=\"Elbow method\")\n",
    "plot_elbow_method(dominis_pca_c[:, 0:11], ax=ax2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ambdos mètodes coincideixen en que el millor valor de k és 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "kmeans_pca_c = cluster.KMeans(n_clusters=2)\n",
    "kmeans_pca_c.fit(dominis_pca_c[:, 0:3])\n",
    "clusters = kmeans_pca_c.labels_\n",
    "c1 = kmeans_pca_c.cluster_centers_[:, 0]\n",
    "c2 = kmeans_pca_c.cluster_centers_[:, 1]\n",
    "c3 = kmeans_pca_c.cluster_centers_[:, 2]\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax = Axes3D(fig)\n",
    "ax.scatter(xs=dominis_pca_c[:, 0], ys=dominis_pca_c[:, 1], zs=dominis_pca_c[:, 2], c=clusters)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# plot the centroids\n",
    "ax.scatter(\n",
    "    c1, c2, c3,\n",
    "    s=150, marker='+',\n",
    "    c='black',\n",
    "    label='centroids'\n",
    ")\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encara que em aplicat un mètode no supervisat, disposem del valors de classificació i podem estudiar si la classificació realitzada s'apropa a la que nosaltres desitjem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "predicted = kmeans_pca_c.predict(X_test_pca_c[:, 0:3])\n",
    "ax = sns.heatmap(confusion_matrix(y_test, predicted), annot=True)\n",
    "ax.set(xlabel=\"Predicted label\", ylabel=\"True label\")\n",
    "print(accuracy_score(predicted, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podem observar com la classificació del model no és ideal encara que aconsegueix un *true positive rate* (sensibilitat) de gairebé perfecte."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusions models<a id='conclusions_model'></a>\n",
    "\n",
    "Després d'haver vist com es comporten els models segons si a més de les columnes de \"contingut\" hi afegim l'estructura de la pàgina web o les tecnologies que aquesta utilitza podem determinar que aquestes variables extra no afecten de manera significativa al model. És més en la majoria dels casos les observacions classificades de manera incorrecta són sempre les mateixes:\n",
    "* Falsos negatius: pàgines web d'empreses però que tenen poca informació i amb els paràmetres extrets de la pàgina web no es poden diferenciar de les que no són empresa.\n",
    "* Falsos positius: pàgines web que no són d'empreses pero hi apareixen telèfons i correus electrònics. Recordem que aquestes dues variables juntes fan pujar entorn al 80% la probabilitat de ser empresa segons el model.\n",
    "\n",
    "Està clar doncs, que amb les dades extretes fins ara dels dominis no és possible obtenir un model superior. El problema rau doncs, com ja s'ha explicat, en pàgines web de no empreses que contenen la informació que nosaltres a priori haviem decidit rellevant per determinar que eren una empresa. Arribata a aquest punt podem:\n",
    "* Acceptar el model creat amb les dades actuals.\n",
    "* Obtenir una mostra més gran de dades. Encara que una mostra major pugui millorar lleugerament el model seguim tenint el problema dels falsos positius perquè les dades són les mateixes.\n",
    "* Afegir noves dades al model:\n",
    "   * Anàlisi NLP.\n",
    "   * Obtenir mètriques de la pàgina web utilitzant [Lighthouse](https://github.com/GoogleChrome/lighthouse). Aquest framework open-source de Google realitza anàlisi de SEO, Accessibilitat o rendiment entre d'altres a les pàgines web. Pot ser un bon enfocament per incrementar les dades encara que pot passar el mateix que amb les tecnologies utilitzades per una pàgina web: que resultin insignificants. De totes maneres cal tenir en compte que Lightouse és una proposta ja realitzada per extreure més indicadors del REPUBLIQUEM.CAT, i que per tant si s'acaba implementant s'hauran d'extreure igualment aquestes dades.\n",
    "\n",
    "De moment, s'agafa el model SVM creat inicialment amb kernel `sigmoid`, `C=50` i `gamma=0.001` i el procedim a aplicar al conjunt total dels dominis i visualitzar-ne els resultats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1,2, figsize=(5,10))\n",
    "probabilitat = svm_c.predict_proba(amb_contingut[contingut_cols])[:, 1]\n",
    "classificacio = svm_c.predict(amb_contingut[contingut_cols])\n",
    "\n",
    "final = pd.DataFrame({\"probabilitat\": probabilitat, \"classificacio\": classificacio})\n",
    "\n",
    "final.groupby(\"classificacio\").size().plot(kind='bar', figsize=(15,7), title=\"Classificació final\", ax=ax2)\n",
    "add_value_labels(ax2)\n",
    "sns.distplot(final.probabilitat, bins=20, ax=ax1, kde=False)\n",
    "ax1.axvline(0.5, color=\"red\", linestyle=\"--\")\n",
    "ax1.set(title=\"Disitrubció probabilitat de ser empresa\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
